# -*-makefile-*-

ifndef SRCLANGS
  SRCLANGS=${SRC}
endif

ifndef SRCLANGS
  TRGLANGS=${TRG}
endif

ifndef THREADS
  THREADS=${HPC_CORES}
endif



CLEAN_TRAIN_SRC = ${patsubst %,${DATADIR}/raw/%.${LANGPAIR}.clean.${SRCEXT}.gz,${TRAINSET}}
CLEAN_TRAIN_TRG = ${patsubst %.${SRCEXT}.gz,%.${TRGEXT}.gz,${CLEAN_TRAIN_SRC}}

CLEAN_TUNE_SRC  = ${patsubst %,${DATADIR}/raw/%.${LANGPAIR}.clean.${SRCEXT}.gz,${TUNESET}}
CLEAN_TUNE_TRG  = ${patsubst %.${SRCEXT}.gz,%.${TRGEXT}.gz,${CLEAN_TUNE_SRC}}

CLEAN_DEV_SRC   = ${patsubst %,${DATADIR}/raw/%.${LANGPAIR}.clean.${SRCEXT}.gz,${DEVSET}}
CLEAN_DEV_TRG   = ${patsubst %.${SRCEXT}.gz,%.${TRGEXT}.gz,${CLEAN_DEV_SRC}}

CLEAN_TEST_SRC  = ${patsubst %,${DATADIR}/raw/%.${LANGPAIR}.clean.${SRCEXT}.gz,${TESTSET}}
CLEAN_TEST_TRG  = ${patsubst %.${SRCEXT}.gz,%.${TRGEXT}.gz,${CLEAN_TEST_SRC}}

DATA_SRC := ${sort ${CLEAN_TRAIN_SRC} ${CLEAN_TUNE_SRC} ${CLEAN_DEV_SRC} ${CLEAN_TEST_SRC}}
DATA_TRG := ${sort ${CLEAN_TRAIN_TRG} ${CLEAN_TUNE_TRG} ${CLEAN_DEV_TRG} ${CLEAN_TEST_TRG}}


clean-data:
	for s in ${SRCLANGS}; do \
	  for t in ${TRGLANGS}; do \
	    ${MAKE} SRC=$$s TRG=$$t clean-data-source; \
	  done \
	done

clean-data-source: ${DATA_SRC}
#	@echo ${LANGPAIR}
#	@echo ${OPUSCORPORA}
#	@echo ${DATA_SRC}



## copy OPUS data
## (check that the OPUS file really exists! if not, create and empty file)

%.${SRCEXT}.raw:
	mkdir -p ${dir $@}
	if [ -e ${OPUSHOME}/${patsubst %.${LANGPAIR}.${SRCEXT}.raw,%,${notdir $@}}/latest/moses/${LANGPAIR}.txt.zip ]; then \
	  scp ${OPUSHOME}/${patsubst %.${LANGPAIR}.${SRCEXT}.raw,%,${notdir $@}}/latest/moses/${LANGPAIR}.txt.zip $@.zip; \
	  unzip -d ${dir $@} $@.zip -x README LICENSE; \
	  mv ${dir $@}${patsubst %.${LANGPAIR}.${SRCEXT}.raw,%,${notdir $@}}*.${LANGPAIR}.${SRCEXT} $@; \
	  mv ${dir $@}${patsubst %.${LANGPAIR}.${SRCEXT}.raw,%,${notdir $@}}*.${LANGPAIR}.${TRGEXT} ${@:.${SRCEXT}.raw=.${TRGEXT}.raw}; \
	  rm -f $@.zip ${@:.${SRCEXT}.raw=.xml} ${@:.${SRCEXT}.raw=.ids} ${dir $@}/README ${dir $@}/LICENSE; \
	else \
	  touch $@; \
	  touch ${@:.${SRCEXT}.raw=.${TRGEXT}.raw}; \
	fi


%.${TRGEXT}.raw: %.${SRCEXT}.raw
	@echo "done!"

## clean data

## this is too strict for non-latin languages
#	grep -i '[a-zäöå0-9]' |\

%.clean.${SRCEXT}.gz: %.${SRCEXT}.tok %.${TRGEXT}.tok
	rm -f $@.${SRCEXT} $@.${TRGEXT}
	ln -s ${word 1,$^} $@.${SRCEXT}
	ln -s ${word 2,$^} $@.${TRGEXT}
	$(MOSESSCRIPTS)/training/clean-corpus-n.perl $@ $(SRCEXT) $(TRGEXT) ${@:.${SRCEXT}.gz=} 0 100
	rm -f $@.${SRCEXT} $@.${TRGEXT}
	paste ${@:.gz=} ${@:.${SRCEXT}.gz=.${TRGEXT}} |\
	perl -CS -pe 'tr[\x{9}\x{A}\x{D}\x{20}-\x{D7FF}\x{E000}-\x{FFFD}\x{10000}-\x{10FFFF}][]cd;' > $@.tmp
	rm -f ${@:.gz=} ${@:.${SRCEXT}.gz=.${TRGEXT}}
	cut -f1 $@.tmp | gzip -c > $@
	cut -f2 $@.tmp | gzip -c > ${@:.${SRCEXT}.gz=.${TRGEXT}.gz}
	rm -f $@.tmp


%.clean.${TRGEXT}.gz: %.clean.${SRCEXT}.gz
	@echo "done!"


# ## add training data for each language combination
# ${TRAIN_SRC}:
# 	mkdir -p ${dir $@}
# 	rm -f ${TRAIN_SRC} ${TRAIN_TRG}
# 	-for s in ${SRCLANGS}; do \
# 	  for t in ${TRGLANGS}; do \
# 	    ${MAKE} DATASET=${DATASET} SRC=$$s TRG=$$t add-to-train-data; \
# 	  done \
# 	done

# ${TRAIN_TRG}: ${TRAIN_SRC}
# 	@echo "done!"


# add-to-train-data: ${CLEAN_TRAIN_SRC}
# ifneq (${words ${TRGLANGS}},1)
# 	echo "more than one target language";
# 	zcat ${CLEAN_TRAIN_SRC} |\
# 	sed "s/^/>>${TRG}<< /" >> ${TRAIN_SRC}
# else
# 	echo "only one target language"
# 	zcat ${CLEAN_TRAIN_SRC} >> ${TRAIN_SRC}
# endif
# 	zcat ${CLEAN_TRAIN_TRG} >> ${TRAIN_TRG}



## add training data for each language combination
## and put it together in local space
${LOCAL_TRAIN_SRC}:
	mkdir -p ${dir $@}
	rm -f ${LOCAL_TRAIN_SRC} ${LOCAL_TRAIN_TRG}
	-for s in ${SRCLANGS}; do \
	  for t in ${TRGLANGS}; do \
	    ${MAKE} DATASET=${DATASET} SRC:=$$s TRG:=$$t \
		add-to-local-train-and-heldout-data; \
	  done \
	done

# 	    ${MAKE} DATASET=${DATASET} SRC:=$$s TRG:=$$t add-to-local-train-data; \

${LOCAL_TRAIN_TRG}: ${LOCAL_TRAIN_SRC}
	@echo "done!"

## TODO: reserve some data for tuning from each corpus
add-to-local-train-data: ${CLEAN_TRAIN_SRC}
ifneq (${CLEAN_TRAIN_SRC},)
	echo "${CLEAN_TRAIN_SRC}" >> ${dir ${LOCAL_TRAIN_SRC}}/README
ifneq (${words ${TRGLANGS}},1)
	echo "more than one target language";
	zcat ${CLEAN_TRAIN_SRC} |\
	sed "s/^/>>${TRG}<< /" >> ${LOCAL_TRAIN_SRC}
else
	echo "only one target language"
	zcat ${CLEAN_TRAIN_SRC} >> ${LOCAL_TRAIN_SRC}
endif
	zcat ${CLEAN_TRAIN_TRG} >> ${LOCAL_TRAIN_TRG}
endif


## extract training data but keep some heldout data for each dataset
add-to-local-train-and-heldout-data: ${CLEAN_TRAIN_SRC}
ifneq (${CLEAN_TRAIN_SRC},)
	echo "${CLEAN_TRAIN_SRC}" >> ${dir ${LOCAL_TRAIN_SRC}}/README
	mkdir -p ${HELDOUT_DIR}
ifneq (${words ${TRGLANGS}},1)
	echo "more than one target language";
	for c in ${CLEAN_TRAIN_SRC}; do \
	  if (( `zcat $$c | head -$$(($(HELDOUTSIZE) + $(HELDOUTSIZE))) | wc -l` == $$(($(HELDOUTSIZE) + $(HELDOUTSIZE))) )); then \
	    zcat $$c | tail -n +$$(($(HELDOUTSIZE) + 1)) |\
	    sed "s/^/>>${TRG}<< /" >> ${LOCAL_TRAIN_SRC}; \
	    zcat $$c | head -$(HELDOUTSIZE) |\
	    sed "s/^/>>${TRG}<< /" | gzip -c \
	    > ${HELDOUT_DIR}/`basename $$c`; \
	  else \
	    zcat $$c | sed "s/^/>>${TRG}<< /" >> ${LOCAL_TRAIN_SRC}; \
	  fi \
	done
else
	echo "only one target language"
	for c in ${CLEAN_TRAIN_SRC}; do \
	  if (( `zcat $$c | head -$$(($(HELDOUTSIZE) + $(HELDOUTSIZE))) | wc -l` == $$(($(HELDOUTSIZE) + $(HELDOUTSIZE))) )); then \
	    zcat $$c | tail -n +$$(($(HELDOUTSIZE) + 1)) >> ${LOCAL_TRAIN_SRC}; \
	    zcat $$c | head -$(HELDOUTSIZE) |\
	    gzip -c > ${HELDOUT_DIR}/`basename $$c`; \
	  else \
	    zcat $$c >> ${LOCAL_TRAIN_SRC}; \
	  fi \
	done
endif
	for c in ${CLEAN_TRAIN_TRG}; do \
	  if (( `zcat $$c | head -$$(($(HELDOUTSIZE) + $(HELDOUTSIZE))) | wc -l` == $$(($(HELDOUTSIZE) + $(HELDOUTSIZE))) )); then \
	    zcat $$c | tail -n +$$(($(HELDOUTSIZE) + 1)) >> ${LOCAL_TRAIN_TRG}; \
	    zcat $$c | head -$(HELDOUTSIZE) |\
	    gzip -c > ${HELDOUT_DIR}/`basename $$c`; \
	  else \
	    zcat $$c >> ${LOCAL_TRAIN_TRG}; \
	  fi \
	done
endif





####################
# development data
####################
#
# make it depending on training data
# --> in case we need more data for development
#     we can take it from training data

${DEV_SRC}: ${TRAIN_SRC}.${PRE_SRC}.gz ${TRAIN_TRG}.${PRE_TRG}.gz
	mkdir -p ${dir $@}
	rm -f ${DEV_SRC} ${DEV_TRG}
	-for s in ${SRCLANGS}; do \
	  for t in ${TRGLANGS}; do \
	    ${MAKE} SRC=$$s TRG=$$t add-to-dev-data; \
	  done \
	done
	paste ${DEV_SRC} ${DEV_TRG} | shuf > $@.shuffled
## if we have less than twice the amount of DEVMINSIZE in the data set
## --> extract some data from the training data to be used as devdata
	if (( `cat $@.shuffled | wc -l` < $$((${DEVMINSIZE} + ${DEVMINSIZE})) )); then \
	  echo "Need more devdata - take some from traindata!"; \
	  echo ".......... (1) extract top $$((${DEVSIZE} + ${TESTSIZE})) lines"; \
	  echo "Too little dev/test data in ${DEVSET}!"                                   >> ${dir $@}/README; \
	  echo "Add top $$((${DEVSIZE} + ${TESTSIZE})) lines from ${DATASET} to dev/test" >> ${dir $@}/README; \
	  echo "and remove those lines from training data"                                >> ${dir $@}/README; \
	  zcat ${TRAIN_SRC}.${PRE_SRC}.gz | \
		head -$$((${DEVSIZE} + ${TESTSIZE})) | \
		sed 's/\@\@ //g' > $@.extra.${SRC}; \
	  zcat ${TRAIN_TRG}.${PRE_TRG}.gz | \
		head -$$((${DEVSIZE} + ${TESTSIZE})) | \
		sed 's/\@\@ //g' > $@.extra.${TRG}; \
	  echo ".......... (2) remaining lines for training"; \
	  zcat ${TRAIN_SRC}.${PRE_SRC}.gz | \
		tail -n +$$((${DEVSIZE} + ${TESTSIZE} + 1)) | \
		sed 's/\@\@ //g' | gzip -c > $@.remaining.${SRC}.gz; \
	  zcat ${TRAIN_TRG}.${PRE_TRG}.gz | \
		tail -n +$$((${DEVSIZE} + ${TESTSIZE} + 1)) | \
		sed 's/\@\@ //g' | gzip -c > $@.remaining.${TRG}.gz; \
	  mv -f $@.remaining.${SRC}.gz ${TRAIN_SRC}.${PRE_SRC}.gz; \
	  mv -f $@.remaining.${TRG}.gz ${TRAIN_TRG}.${PRE_TRG}.gz; \
	  echo ".......... (3) append to devdata"; \
	  mv $@.shuffled $@.oldshuffled; \
	  paste $@.extra.${SRC} $@.extra.${TRG} > $@.shuffled; \
	  cat $@.oldshuffled >> $@.shuffled; \
	  rm $@.oldshuffled; \
	  rm -f $@.extra.${SRC} $@.extra.${TRG}; \
	fi
## if we extract test and dev data from the same data set
## ---> make sure that we do not have any overlap between the two data sets
## ---> reserve at least DEVMINSIZE data for dev data and keep the rest for testing
ifeq (${DEVSET},${TESTSET})
	if (( `cat $@.shuffled | wc -l` < $$((${DEVSIZE} + ${TESTSIZE})) )); then \
	  echo "devset = top ${DEVMINSIZE} lines of $@.shuffled!"  >> ${dir $@}/README; \
	  cut -f1 $@.shuffled | head -${DEVMINSIZE} > ${DEV_SRC}; \
	  cut -f2 $@.shuffled | head -${DEVMINSIZE} > ${DEV_TRG}; \
	  mkdir -p ${dir ${TEST_SRC}}; \
	  echo "testset = top ${DEVMINSIZE} lines of $@.shuffled!"  >> ${dir ${TEST_SRC}}/README; \
	  cut -f1 $@.shuffled | tail -n +$$((${DEVMINSIZE} + 1)) > ${TEST_SRC}; \
	  cut -f2 $@.shuffled | tail -n +$$((${DEVMINSIZE} + 1)) > ${TEST_TRG}; \
	else
	  echo "devset = top ${DEVSIZE} lines of $@.shuffled!"  >> ${dir $@}/README; \
	  cut -f1 $@.shuffled | head -${DEVSIZE} > ${DEV_SRC}; \
	  cut -f2 $@.shuffled | head -${DEVSIZE} > ${DEV_TRG}; \
	  mkdir -p ${dir ${TEST_SRC}}; \
	  echo "testset = top ${DEVSIZE} lines of $@.shuffled!"  >> ${dir ${TEST_SRC}}/README; \
	  cut -f1 $@.shuffled | tail -${TESTSIZE} > ${TEST_SRC}; \
	  cut -f2 $@.shuffled | tail -${TESTSIZE} > ${TEST_TRG}; \
	fi
else
	echo "devset = top ${DEVSIZE} lines of $@.shuffled!"  >> ${dir $@}/README
	cut -f1 $@.shuffled | head -${DEVSIZE} > ${DEV_SRC}
	cut -f2 $@.shuffled | head -${DEVSIZE} > ${DEV_TRG}
endif
	gzip -f $@.shuffled


${DEV_TRG}: ${DEV_SRC}
	@echo "done!"


add-to-dev-data: ${CLEAN_DEV_SRC}
ifneq (${CLEAN_DEV_SRC},)
ifneq (${words ${TRGLANGS}},1)
	echo "more than one target language";
	zcat ${CLEAN_DEV_SRC} |\
	sed "s/^/>>${TRG}<< /" >> ${DEV_SRC}
else
	echo "only one target language"
	zcat ${CLEAN_DEV_SRC} >> ${DEV_SRC}
endif
	zcat ${CLEAN_DEV_TRG} >> ${DEV_TRG}
endif


####################
# test data
####################

${TEST_SRC}: ${DEV_SRC}
ifneq (${TESTSET},${DEVSET})
	mkdir -p ${dir $@}
	rm -f ${TEST_SRC} ${TEST_TRG}
	-if [ -e ${TESTSET}.${SRC}.gz ]; then \
	  ${MAKE} CLEAN_TEST_SRC=${TESTSET}.${SRC}.gz \
		  CLEAN_TEST_TRG=${TESTSET}.${TRG}.gz \
	  add-to-test-data; \
	else \
	  for s in ${SRCLANGS}; do \
	    for t in ${TRGLANGS}; do \
	      ${MAKE} SRC=$$s TRG=$$t add-to-test-data; \
	    done \
	  done \
	fi
	if [ ${TESTSIZE} -lt `cat $@ | wc -l` ]; then \
	  paste ${TEST_SRC} ${TEST_TRG} | shuf > $@.shuffled; \
	  cut -f1 $@.shuffled | tail -${TESTSIZE} > ${TEST_SRC}; \
	  cut -f2 $@.shuffled | tail -${TESTSIZE} > ${TEST_TRG}; \
	  echo "testset = top ${TESTSIZE} lines of $@.shuffled!" >> ${dir $@}/README; \
	fi
else
	mkdir -p ${dir $@}
	if (( `cat $<.shuffled | wc -l` < $$((${DEVSIZE} + ${TESTSIZE})) )); then \
	  cut -f1 $<.shuffled | tail -n +$$((${DEVMINSIZE} + 1)) > ${TEST_SRC}; \
	  cut -f2 $<.shuffled | tail -n +$$((${DEVMINSIZE} + 1)) > ${TEST_TRG}; \
	else \
	  cut -f1 $<.shuffled | tail -${TESTSIZE} > ${TEST_SRC}; \
	  cut -f2 $<.shuffled | tail -${TESTSIZE} > ${TEST_TRG}; \
	fi
endif

${TEST_TRG}: ${TEST_SRC}
	@echo "done!"

add-to-test-data: ${CLEAN_TEST_SRC}
ifneq (${CLEAN_TEST_SRC},)
ifneq (${words ${TRGLANGS}},1)
	echo "more than one target language";
	zcat ${CLEAN_TEST_SRC} |\
	sed "s/^/>>${TRG}<< /" >> ${TEST_SRC}
else
	echo "only one target language"
	zcat ${CLEAN_TEST_SRC} >> ${TEST_SRC}
endif
	zcat ${CLEAN_TEST_TRG} >> ${TEST_TRG}
endif






####################
# tune data
####################

${TUNE_SRC}: ${TRAIN_SRC}
	mkdir -p ${dir $@}
	rm -f ${TUNE_SRC} ${TUNE_TRG}
	-for s in ${SRCLANGS}; do \
	  for t in ${TRGLANGS}; do \
	    ${MAKE} SRC=$$s TRG=$$t add-to-tune-data; \
	  done \
	done

${TUNE_TRG}: ${TUNE_SRC}
	@echo "done!"

add-to-tune-data: ${CLEAN_TUNE_SRC}
ifneq (${CLEAN_TUNE_SRC},)
ifneq (${words ${TRGLANGS}},1)
	echo "more than one target language";
	zcat ${CLEAN_TUNE_SRC} |\
	sed "s/^/>>${TRG}<< /" >> ${TUNE_SRC}
else
	echo "only one target language"
	zcat ${CLEAN_TUNE_SRC} >> ${TUNE_SRC}
endif
	zcat ${CLEAN_TUNE_TRG} >> ${TUNE_TRG}
endif



##----------------------------------------------
## tokenization
##----------------------------------------------


## normalisation for Chinese
%.zh_tw.tok: %.zh_tw.raw
	$(LOAD_MOSES) cat $< |\
	$(TOKENIZER)/replace-unicode-punctuation.perl |\
	$(TOKENIZER)/remove-non-printing-char.perl |\
	$(TOKENIZER)/normalize-punctuation.perl |\
	sed 's/  */ /g;s/^ *//g;s/ *$$//g' > $@

%.zh_cn.tok: %.zh_cn.raw
	$(LOAD_MOSES) cat $< |\
	$(TOKENIZER)/replace-unicode-punctuation.perl |\
	$(TOKENIZER)/remove-non-printing-char.perl |\
	$(TOKENIZER)/normalize-punctuation.perl |\
	sed 's/  */ /g;s/^ *//g;s/ *$$//g' > $@

%.zh.tok: %.zh.raw
	$(LOAD_MOSES) cat $< |\
	$(TOKENIZER)/replace-unicode-punctuation.perl |\
	$(TOKENIZER)/remove-non-printing-char.perl |\
	$(TOKENIZER)/normalize-punctuation.perl |\
	sed 's/  */ /g;s/^ *//g;s/ *$$//g' > $@

## generic target for tokenization
%.tok: %.raw
	$(LOAD_MOSES) cat $< |\
	$(TOKENIZER)/replace-unicode-punctuation.perl |\
	$(TOKENIZER)/remove-non-printing-char.perl |\
	$(TOKENIZER)/normalize-punctuation.perl \
		-l ${lastword ${subst 1,,${subst 2,,${subst ., ,$(<:.raw=)}}}} |\
	$(TOKENIZER)/tokenizer.perl -a -threads $(THREADS) \
		-l ${lastword ${subst 1,,${subst 2,,${subst ., ,$(<:.raw=)}}}} |\
	sed 's/  */ /g;s/^ *//g;s/ *$$//g' > $@





############## OLD ##########################################
## without aggressive tokenisation of hyphens
## and without HTML escaping
## no special treatment of contracted forms in English
##
## NEW: (above) make compatible with python wrapper of 
##      the mosestokenizer tools
#############################################################

# ## tokenization for English
# %.en.tok: %.en.raw
# 	$(LOAD_MOSES) cat $< |\
# 	$(TOKENIZER)/replace-unicode-punctuation.perl |\
# 	$(TOKENIZER)/remove-non-printing-char.perl |\
# 	$(TOKENIZER)/normalize-punctuation.perl -l en |\
# 	$(TOKENIZER)/pre-tokenizer.perl -l en |\
# 	sed -e "s/it's/it is/g" \
# 		-e "s/It's/It is/g" \
# 		-e "s/That's/That is/g" \
# 		-e "s/What's/What is/g" \
# 		-e "s/She's/She is/g" \
# 		-e "s/He's/He is/g" \
# 		-e "s/We've/We have/g" \
# 		-e "s/We're/We are/g" \
# 		-e "s/They're/They are/g" \
# 		-e "s/There's/There is/g" \
# 		-e "s/What's/What is/g" \
# 		-e "s/didn't/did not/g" \
# 		-e "s/don't/do not/g" \
# 		-e "s/can't/cannot/g" \
# 		-e "s/they're/they are/g" \
# 		-e "s/that's/that is/g" \
# 		-e "s/he's/he is/g" \
# 		-e "s/wasn't/was not/g" \
# 		-e "s/she's/she is/g" \
# 		-e "s/couldn't/could not/g" \
# 		-e "s/we're/we are/g" \
# 		-e "s/you're/you are/g" \
# 		-e "s/we've/we have/g" \
# 		-e "s/doesn't/does not/g" \
# 		-e "s/weren't/were not/g" \
# 		-e "s/isn't/is not/g" \
# 		-e "s/haven't/have not/g" \
# 		-e "s/hadn't/had not/g" \
# 		-e "s/would've/would have/g" \
# 		-e "s/wouldn't/would not/g" \
# 		-e "s/won't/will not/g" \
# 		-e "s/we'll/we will/g" \
# 		-e "s/we'd/we would/g" \
# 		-e "s/she'd/she would/g" \
# 		-e "s/he'll/he will/g" \
# 		-e "s/he'd/he would/g" \
# 		-e "s/I'm/I am/g" \
# 		-e "s/here's/here is/g" \
# 		-e "s/I've/I have/g" \
# 		-e "s/I'v/I have/g" \
# 		-e "s/I'd/I would/g" \
# 		-e "s/He'd/He would/g" \
# 		-e "s/hasn't/has not/g" |\
# 	$(TOKENIZER)/tokenizer.perl -no-escape -threads $(THREADS) -l en |\
# 	sed 's/  */ /g;s/^ *//g;s/ *$$//g' > $@

# ## generic target for tokenization
# %.tok: %.raw
# 	$(LOAD_MOSES) cat $< |\
# 	$(TOKENIZER)/replace-unicode-punctuation.perl |\
# 	$(TOKENIZER)/remove-non-printing-char.perl |\
# 	$(TOKENIZER)/normalize-punctuation.perl \
# 		-l ${lastword ${subst ., ,$(<:.raw=)}} |\
# 	$(TOKENIZER)/tokenizer.perl -no-escape -threads $(THREADS) \
# 		-l ${lastword ${subst ., ,$(<:.raw=)}} |\
# 	sed 's/  */ /g;s/^ *//g;s/ *$$//g' > $@



##----------------------------------------------
## BPE
##----------------------------------------------

## source/target specific bpe
## - make sure to leave the language flags alone!
## - make sure that we do not delete the BPE code files
## if the BPE models already exist
## ---> do not create new ones and always keep the old ones
## ---> need to delete the old ones if we want to create new BPE models


BPESRCMODEL = ${TRAIN_SRC}.bpe${SRCBPESIZE:000=}k-model
BPETRGMODEL = ${TRAIN_TRG}.bpe${TRGBPESIZE:000=}k-model

.PRECIOUS: ${BPESRCMODEL} ${BPETRGMODEL}
.INTERMEDIATE: ${LOCAL_TRAIN_SRC} ${LOCAL_TRAIN_TRG}

${BPESRCMODEL}: ${WORKDIR}/%.bpe${SRCBPESIZE:000=}k-model: ${TMPDIR}/%
ifeq ($(wildcard ${BPESRCMODEL}),)
	mkdir -p ${dir $@}
ifeq ($(TRGLANGS),${firstword ${TRGLANGS}})
	python3 ${SNMTPATH}/learn_bpe.py -s $(SRCBPESIZE) < $< > $@
else
	cut -f2- -d ' ' $< > $<.text
	python3 ${SNMTPATH}/learn_bpe.py -s $(SRCBPESIZE) < $<.text > $@
	rm -f $<.text
endif
else
	@echo "$@ already exists!"
	@echo "WARNING! No new BPE model is created even though the data has changed!"
	@echo "WARNING! Delete the file if you want to start from scratch!"
	touch $@
endif

## no labels on the target language side
${BPETRGMODEL}: ${WORKDIR}/%.bpe${TRGBPESIZE:000=}k-model: ${TMPDIR}/%
ifeq ($(wildcard ${BPETRGMODEL}),)
	mkdir -p ${dir $@}
	python3 ${SNMTPATH}/learn_bpe.py -s $(TRGBPESIZE) < $< > $@
else
	@echo "$@ already exists!"
	@echo "WARNING! No new BPE codes are created!"
	@echo "WARNING! Delete the file if you want to start from scratch!"
	touch $@
endif



%.src.${PRE_SRC}: %.src ${BPESRCMODEL}
ifeq ($(TRGLANGS),${firstword ${TRGLANGS}})
	python3 ${SNMTPATH}/apply_bpe.py -c $(word 2,$^) < $< > $@
else
	cut -f1 -d ' ' $< > $<.labels
	cut -f2- -d ' ' $< > $<.text
	python3 ${SNMTPATH}/apply_bpe.py -c $(word 2,$^) < $<.text > $@.text
	paste -d ' ' $<.labels $@.text > $@
	rm -f $<.labels $<.text $@.text
endif

%.trg.${PRE_TRG}: %.trg ${BPETRGMODEL}
	python3 ${SNMTPATH}/apply_bpe.py -c $(word 2,$^) < $< > $@



# %.trg.${PRE_TRG}.gz: %.trg.${PRE_TRG}
# 	gzip -f $<

# %.src.${PRE_SRC}.gz: %.src.${PRE_SRC}
# 	gzip -f $<


## get it from local space and compress ...
${WORKDIR}/%.trg.${PRE_TRG}.gz: ${TMPDIR}/%.trg.${PRE_TRG}
	gzip -c < $< > $@

${WORKDIR}/%.src.${PRE_SRC}.gz: ${TMPDIR}/%.src.${PRE_SRC}
	gzip -c < $< > $@
